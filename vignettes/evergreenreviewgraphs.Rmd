---
title: "#evergreenreview graphs"
author: "Najko Jahn"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteIndexEntry{Overview}
  \usepackage[utf8]{inputenc}
---

```{r, echo=FALSE}
knitr::opts_chunk$set(
  comment = "#>",
  collapse = TRUE,
  warning = FALSE,
  message = FALSE,
  echo = TRUE,
  fig.width = 7,
  fig.height = 4
)
options(scipen = 999, digits = 2)
knitr::knit_hooks$set(inline = function(x) {
      if(is.numeric(x)){
          return(prettyNum(x, big.mark=","))
      }else{
          return(x)
       }
   })
```

## What is a evergreen review graph?

<http://www.masalmon.eu/2017/05/14/evergreenreviewgraph/>

## Preparing proper review graphs with `epmc_hits_trend()`


## Use Cases 

### Use Case: Growth of Open Access Literature

There is a growing interest in knowing the proportion of open access to scholarly literature. Europe PMC allows searching for open access content with with the [`OPEN_ACCESS:Y` parameter](https://europepmc.org/search?query=OPEN_ACCESS:Y&page=1&sortby=Relevance). At the moment, Europe PMC contains `r europepmc::epmc_hits("OPEN_ACCESS:Y")` open access fulltexts. Let's see how they are relatively distributed over the period 1995 - 2016.

```{r, fig.align='center'}
tt_oa <- europepmc::epmc_hits_trend("OPEN_ACCESS:Y", period = 1995:2016, synonym = FALSE)
tt_oa
# we use ggplot2 for plotting the graph
library(ggplot2)
ggplot(tt_oa, aes(year, query_hits / all_hits)) + 
  geom_point() + 
  geom_line() +
  xlab("Year published") + 
  ylab("Proportion of OA full-texts in Europe PMC")
```

Be careful with your interpretation of the last years because Europe PMC also contains journals, which make their articles openly available after an embargo period (up to two years). 

### Use Case: Citing open source software in scholarly publications

Another nice use case for review graphs is to show how code and software repositories are cited in scientific literature. It is considered to be a good practise not only to re-use openly available software, but also to cite them. The [FORCE11 Software Citation Working Group](https://www.force11.org/group/software-citation-working-group) states:

> In general, we believe that software should be cited on the same basis as any other research product such as a paper or book; that is, authors should cite the appropriate set of software products just as they cite the appropriate set of papers. [(doi:10.7717/peerj-cs.86)](https://doi.org/10.7717/peerj-cs.86)

So let's see whether we can find evidence for this evolving practise by creating a proper review graph. As a start, we examine these four general purpose hosting services for version-controlled code:

- code.google.com
- github.com
- sourceforge.net
- bitbucket.org

and, of course, CRAN, the R archive network.

#### How to query Europe PMC?

We only want to search reference sections. Notice that Europe PMC does not index reference sections for its complete collection. To search reference, we use `REF:` parameter and `has_reflist:y` to restrict our search to those publications where Europe PMC indexed the reference section.

Let's prepare the queries for links to the above mentioned code hosting services:

```{r}
dvcs <- c("code.google.com", "github.com", 
          "sourceforge.net", "bitbucket.org", "cran.r-project.org")
# make queries including reference section
dvcs_query <- paste0('REF:"', dvcs, '"')
```

and use only those publications for which Europe PMC has a reference list for normalising the review graph.

```{r}
library(dplyr)
my_df <- lapply(dvcs_query, function(x) {
  refs_hits <- 
    europepmc::epmc_hits_trend("has_reflist:y", period = 2009:2016, synonym = FALSE)$query_hits
  europepmc::epmc_hits_trend(x, period = 2009:2016, synonym = FALSE) %>% 
    cbind(refs_hits, query_id = x) %>%
    dplyr::select(year, all_hits, refs_hits, query_hits, query_id)
}) %>%
  dplyr::bind_rows() %>%
  dplyr::as_data_frame()
my_df
```

Comparing `all_hits`, all Medline indexed publications, with `ref_hits`, publications with indexed reference sections, reveals that the proportion of papers where Europe PMC was able to make the reference sections available was `r round(sum(my_df$refs_hits) / sum(my_df$all_hits), digits = 2)` for the period 2009-2016. It also seems that there is a time-lag between indexing a publication and reference section because the absolute number of reference is decreasing over the years. This is presumably because Europe PMC also includes mandated open access journals, i.e. journals which make their content freely available after a certain period of time.

Let's make a proper review graph normalising our query results with the number of publications with indexed reference sections.

```{r}
library(ggplot2)
ggplot(my_df, aes(year, query_hits / refs_hits, group = query_id, 
                  color = query_id)) +
  geom_line(size = 1, alpha = 0.8) +
  geom_point(size = 2) +
  scale_color_brewer(name = "Query", palette = "Set1") 
```

#### Discussion

Although this figure illustrates the relative popularity of citing code hosted by CRAN and GitHub in recent years, there are some limits that needs to be discussed. Europe PMC does not index all reference sections from publications, but only if they have access to the full-text or if publishers made it available to Europe PMC. It furthermore remains open whether and to what extent software is cited outside the reference section, i.e. as footnote or in the acknowledgement. 

Another problem of our query approach is that we did not take into consideration that DOIs can also be used to cite software, a best-practise supported by [Zenodo and GitHub](https://guides.github.com/activities/citable-code/) or the [The Journal of Open Source Software](http://joss.theoj.org/). 

Lastly, it actually remains unclear, which and what kind of software is cited how often. We could not control if authors simply cited the code hosting service or CRAN network to show that they used R instead of a repository. One paper can also cite more than one code repository, which is also not represented in our data. 

To conclude, a proper review graph on the extent of software citation can only be the start for a more sophisticated approach that mines links to software repositories from scientific literature and fetches metadata about these code repositories from the hosting facilities.

